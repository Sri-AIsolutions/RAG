{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4db09e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "224591e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "#from langchain.schema import Document\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "#from langchain_community.vectorstores import chroma\n",
    "from langchain_chroma import Chroma\n",
    "#utility imports\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9bfbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG ARCHITECTURE:\n",
      "      1. Document Loading: Loading required documents\n",
      "      2.Document Splitting: Breaking documets into small chunks\n",
      "      3.Embedding Generation: Converting all the embeddings into vectors\n",
      "      4.vector store: storing all the vectors into chromadb\n",
      "      5.Query processing: converting user query to vector embedding\n",
      "      6.Sinilarity search: Finding relevant chunks from the vector store\n",
      "      7.Context Augmentation:combine retrieved chunks with the query\n",
      "      8.Response generation:LLM generates answers using context\n",
      "\n",
      "\n",
      "     it is used to reduce the hallucinations\n",
      "     provide upto date informations\n",
      "      it allows to work with domain specific knowldge\n",
      "      it reduces training cost unlike fine tuning \n"
     ]
    }
   ],
   "source": [
    "#RAG IMPLIMENTATION\n",
    "print(\"\"\"\n",
    "RAG ARCHITECTURE:\n",
    "      1. Document Loading: Loading required documents\n",
    "      2.Document Splitting: Breaking documets into small chunks\n",
    "      3.Embedding Generation: Converting all the embeddings into vectors\n",
    "      4.vector store: storing all the vectors into chromadb\n",
    "      5.Query processing: converting user query to vector embedding\n",
    "      6.Sinilarity search: Finding relevant chunks from the vector store\n",
    "      7.Context Augmentation:combine retrieved chunks with the query\n",
    "      8.Response generation:LLM generates answers using context\n",
    "\"\"\")\n",
    "print(\"\"\"\n",
    "     it is used to reduce the hallucinations\n",
    "     provide upto date informations\n",
    "      it allows to work with domain specific knowldge\n",
    "      it reduces training cost unlike fine tuning \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c0b6401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.\\n    ',\n",
       " '\\nSri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \\n than relying solely on pretrained model knowledge.\\n',\n",
       " '\\nBeyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving libraries. \\n With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \\n highly-paid machine learning engineer.\\n']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=[\n",
    "    \"\"\"\n",
    "   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \n",
    "   With a strong curiosity about how intelligent systems function, Sri is focused on building \n",
    "   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\n",
    "     strongly prefers a hands-on, project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \n",
    "     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "Sri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\n",
    " This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \n",
    " At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \n",
    " A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \n",
    " than relying solely on pretrained model knowledge.\n",
    "\"\"\",\n",
    "\n",
    "\"\"\"\n",
    "Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \n",
    "There is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \n",
    "ultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\n",
    " values updated, correct, and production-ready code, especially when working with fast-evolving libraries. \n",
    " With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \n",
    " highly-paid machine learning engineer.\n",
    "\"\"\"\n",
    "]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "149d0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpe2g_gknc\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b517ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\tmpe2g_gknc'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f32a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview:\n",
      "\n",
      "   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \n",
      "   With a strong curiosity about how intellig...\n"
     ]
    }
   ],
   "source": [
    "#STEP1:  -----> DOCUMENT LOADING\n",
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "# Load documents from directory\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", \n",
    "    glob=\"*.txt\", \n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5220ce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='\\n   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\nSri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \\n than relying solely on pretrained model knowledge.\\n'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\nBeyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving libraries. \\n With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \\n highly-paid machine learning engineer.\\n')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffb7cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. ...\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "#step2----->DOCUMENT SPLITTING\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Maximum size of each chunk\n",
    "    chunk_overlap=50,  # Overlap between chunks to maintain context\n",
    "    length_function=len,\n",
    "    separators=[\" \"]  # Hierarchy of separators\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d1cb19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS can be created using openaiembeddings but \n",
      "\"vectorstore(chromadb) --->converts chunks into embeddings(provided api for openai...it uses any embedding model )-->stores it--->does similarity search also.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"EMBEDDINGS can be created using openaiembeddings but \n",
    "\"vectorstore(chromadb) --->converts chunks into embeddings(provided api for openai...it uses any embedding model )-->stores it--->does similarity search also.\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da99fc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Sri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='like LangChain. \\n A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \\n than relying solely on pretrained model knowledge.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='code, especially when working with fast-evolving libraries. \\n With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \\n highly-paid machine learning engineer.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32b499ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initializing Chromadb and storing chunks in it\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "initializing Chromadb and storing chunks in it\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d814d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 6 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "## Create a Chromdb vector store\n",
    "persist_directory=\"./chroma_db\"\n",
    "\n",
    "## Initialize Chromadb with Open AI embeddings\n",
    "vectorstore=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    "\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0784100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store has 6 vectors\n"
     ]
    }
   ],
   "source": [
    "#just to load--without duplicating the vectors\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Load existing vectorstore\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store has {vectorstore._collection.count()} vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f29e086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vectorstore.delete_collection()\n",
    "\n",
    "#print(\"Collection deleted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b7543e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top 3 chunks are picked from similarity search--LLM IS NOT INVOLVED YET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SIMILARITY SEARCH----->\n",
    "query=\"what does sri enjoys doing??\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "top 3 chunks are picked from similarity search--LLM IS NOT INVOLVED YET\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ea6c026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChromaDB stores 4 main things.\n",
      "\n",
      "1.Embeddings (Vectors) \n",
      "These are the numerical representations of your text.\n",
      "\n",
      "2.Original Text (Document Content)\n",
      "The actual text chunk---Not just the vector cause After similarity search, you need the original text to send to the LLM\n",
      "\n",
      "3.Metadata\n",
      "Metadata is extra information about each chunk\n",
      "\n",
      "4.Internal IDs & Indexes \n",
      "ChromaDB also stores:\n",
      "-->Unique IDs for each vector\n",
      "-->Index structures (for fast search)\n",
      "-->Collection information\n",
      "-->You usually don't interact with this directly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "ChromaDB stores 4 main things.\n",
    "\n",
    "1.Embeddings (Vectors) \n",
    "These are the numerical representations of your text.\n",
    "\n",
    "2.Original Text (Document Content)\n",
    "The actual text chunk---Not just the vector cause After similarity search, you need the original text to send to the LLM\n",
    "\n",
    "3.Metadata\n",
    "Metadata is extra information about each chunk\n",
    "\n",
    "4.Internal IDs & Indexes \n",
    "ChromaDB also stores:\n",
    "-->Unique IDs for each vector\n",
    "-->Index structures (for fast search)\n",
    "-->Collection information\n",
    "-->You usually don't interact with this directly\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aeaa5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert vector store to retriever\n",
    "#create document chain\n",
    "#create rag chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c348ad31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='8816f372-193e-4812-b103-f56ce48fe282', metadata={'source': 'data\\\\doc_0.txt'}, page_content='project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.'),\n",
       "  0.3926195502281189),\n",
       " (Document(id='e3e6f5d8-9fb0-4299-95e8-52a9db7931ea', metadata={'source': 'data\\\\doc_2.txt'}, page_content='Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving'),\n",
       "  0.3948098123073578),\n",
       " (Document(id='c2f6cf0e-5c36-4767-a7b0-62f311cab81a', metadata={'source': 'data\\\\doc_0.txt'}, page_content='Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as'),\n",
       "  0.4037918746471405)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"what is Deep Learning?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs\n",
    "\n",
    "\n",
    "#similarity search with scores\n",
    "results_scores=vectorstore.similarity_search_with_score(query,k=3)\n",
    "results_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ba108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b6f530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model_name=\"gpt-5-nano\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b363deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025A06C6C050>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retriever\n",
    "retriever=vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\":3} ## Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b54c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c4c56d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26f08183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 272000, 'max_output_tokens': 128000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000025A06C52520>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025A06C50640>, root_client=<openai.OpenAI object at 0x0000025A06D289B0>, root_async_client=<openai.AsyncOpenAI object at 0x0000025A06D28AA0>, model_name='gpt-5-nano', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATING DOCUMENT CHAIN\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48bdaefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025A06C6C050>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(profile={'max_input_tokens': 272000, 'max_output_tokens': 128000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000025A06C52520>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025A06C50640>, root_client=<openai.OpenAI object at 0x0000025A06D289B0>, root_async_client=<openai.AsyncOpenAI object at 0x0000025A06D28AA0>, model_name='gpt-5-nano', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "\n",
    "# Usage remains the same\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "rag_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e263073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'who is sri, and what does she enjoy doing the most?? tell me in 500 words',\n",
       " 'context': [Document(id='e3e6f5d8-9fb0-4299-95e8-52a9db7931ea', metadata={'source': 'data\\\\doc_2.txt'}, page_content='Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving'),\n",
       "  Document(id='c2f6cf0e-5c36-4767-a7b0-62f311cab81a', metadata={'source': 'data\\\\doc_0.txt'}, page_content='Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as'),\n",
       "  Document(id='b016867d-3839-405f-aae9-6c58ac1ffb6d', metadata={'source': 'data\\\\doc_1.txt'}, page_content='Sri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding')],\n",
       " 'answer': 'Sri is a passionate, highly motivated learner who is actively transitioning into machine learning, deep learning, and Generative AI. She enjoys exploring emerging technologies—such as Generative AI, Agentic AI, chatbots, and multimodal systems—and is focused on building end-to-end AI systems that go from raw data ingestion to embeddings, vector search, and context-aware responses using large language models. She thrives on hands-on, project-based learning, values production-ready code and practical foundations (Python, data structures, model training, deployment), and is pursuing AI-driven healthcare applications like MRI-based cancer detection while also learning Retrieval-Augmented Generation, vector databases, embeddings, and LangChain.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=rag_chain.invoke({\"input\":\"who is sri, and what does she enjoy doing the most?? tell me in 500 words\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c146db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
