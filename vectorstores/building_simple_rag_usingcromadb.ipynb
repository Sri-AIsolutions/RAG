{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db09e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224591e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "#from langchain.schema import Document\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "#from langchain_community.vectorstores import chroma\n",
    "from langchain_chroma import Chroma\n",
    "#utility imports\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9bfbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG ARCHITECTURE:\n",
      "      1. Document Loading: Loading required documents\n",
      "      2.Document Splitting: Breaking documets into small chunks\n",
      "      3.Embedding Generation: Converting all the embeddings into vectors\n",
      "      4.vector store: storing all the vectors into chromadb\n",
      "      5.Query processing: converting user query to vector embedding\n",
      "      6.Sinilarity search: Finding relevant chunks from the vector store\n",
      "      7.Context Augmentation:combine retrieved chunks with the query\n",
      "      8.Response generation:LLM generates answers using context\n",
      "\n",
      "\n",
      "     it is used to reduce the hallucinations\n",
      "     provide upto date informations\n",
      "      it allows to work with domain specific knowldge\n",
      "      it reduces training cost unlike fine tuning \n"
     ]
    }
   ],
   "source": [
    "#RAG IMPLIMENTATION\n",
    "print(\"\"\"\n",
    "RAG ARCHITECTURE:\n",
    "      1. Document Loading: Loading required documents\n",
    "      2.Document Splitting: Breaking documets into small chunks\n",
    "      3.Embedding Generation: Converting all the embeddings into vectors\n",
    "      4.vector store: storing all the vectors into chromadb\n",
    "      5.Query processing: converting user query to vector embedding\n",
    "      6.Sinilarity search: Finding relevant chunks from the vector store\n",
    "      7.Context Augmentation:combine retrieved chunks with the query\n",
    "      8.Response generation:LLM generates answers using context\n",
    "\"\"\")\n",
    "print(\"\"\"\n",
    "     it is used to reduce the hallucinations\n",
    "     provide upto date informations\n",
    "      it allows to work with domain specific knowldge\n",
    "      it reduces training cost unlike fine tuning \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0b6401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.\\n    ',\n",
       " '\\nSri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \\n than relying solely on pretrained model knowledge.\\n',\n",
       " '\\nBeyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving libraries. \\n With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \\n highly-paid machine learning engineer.\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=[\n",
    "    \"\"\"\n",
    "   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \n",
    "   With a strong curiosity about how intelligent systems function, Sri is focused on building \n",
    "   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\n",
    "     strongly prefers a hands-on, project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \n",
    "     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "Sri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\n",
    " This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \n",
    " At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \n",
    " A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \n",
    " than relying solely on pretrained model knowledge.\n",
    "\"\"\",\n",
    "\n",
    "\"\"\"\n",
    "Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \n",
    "There is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \n",
    "ultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\n",
    " values updated, correct, and production-ready code, especially when working with fast-evolving libraries. \n",
    " With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \n",
    " highly-paid machine learning engineer.\n",
    "\"\"\"\n",
    "]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149d0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpuyrge44k\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b517ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\tmpuyrge44k'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f32a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview:\n",
      "\n",
      "   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \n",
      "   With a strong curiosity about how intellig...\n"
     ]
    }
   ],
   "source": [
    "#STEP1:  -----> DOCUMENT LOADING\n",
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "# Load documents from directory\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", \n",
    "    glob=\"*.txt\", \n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5220ce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='\\n   Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\nSri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \\n than relying solely on pretrained model knowledge.\\n'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\nBeyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving libraries. \\n With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \\n highly-paid machine learning engineer.\\n')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb7cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. ...\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "#step2----->DOCUMENT SPLITTING\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Maximum size of each chunk\n",
    "    chunk_overlap=50,  # Overlap between chunks to maintain context\n",
    "    length_function=len,\n",
    "    separators=[\" \"]  # Hierarchy of separators\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1cb19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS can be created using openaiembeddings but \n",
      "\"vectorstore(chromadb) --->converts chunks into embeddings(provided api for openai...it uses any embedding model )-->stores it--->does similarity search also.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"EMBEDDINGS can be created using openaiembeddings but \n",
    "\"vectorstore(chromadb) --->converts chunks into embeddings(provided api for openai...it uses any embedding model )-->stores it--->does similarity search also.\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da99fc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Sri has a growing interest in AI-driven healthcare solutions, particularly in cancer detection using MRI and medical imaging.\\n This interest has led to working on literature surveys, studying CNN architectures, and exploring how image processing techniques can support early and accurate diagnosis. \\n At the same time, Sri is actively learning about Retrieval-Augmented Generation (RAG) systems, vector databases, embeddings, and modern AI frameworks like LangChain. \\n A key focus is understanding'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='like LangChain. \\n A key focus is understanding how documents are split, embedded, stored, and retrieved, enabling intelligent systems to reason over custom knowledge bases rather \\n than relying solely on pretrained model knowledge.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='code, especially when working with fast-evolving libraries. \\n With consistent effort, curiosity, and a strong preference for learning by doing, Sri is steadily developing the skills required to become a high-impact, \\n highly-paid machine learning engineer.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b499ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initializing Chromadb and storing chunks in it\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "initializing Chromadb and storing chunks in it\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d814d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 6 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "## Create a Chromdb vector store\n",
    "persist_directory=\"./chroma_db\"\n",
    "\n",
    "## Initialize Chromadb with Open AI embeddings\n",
    "vectorstore=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    "\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vectorstore.delete_collection()\n",
    "\n",
    "#print(\"Collection deleted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b7543e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top 3 chunks are picked from similarity search--LLM IS NOT INVOLVED YET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SIMILARITY SEARCH----->\n",
    "query=\"what does sri enjoys doing??\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "top 3 chunks are picked from similarity search--LLM IS NOT INVOLVED YET\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea6c026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChromaDB stores 4 main things.\n",
      "\n",
      "1.Embeddings (Vectors) \n",
      "These are the numerical representations of your text.\n",
      "\n",
      "2.Original Text (Document Content)\n",
      "The actual text chunk---Not just the vector cause After similarity search, you need the original text to send to the LLM\n",
      "\n",
      "3.Metadata\n",
      "Metadata is extra information about each chunk\n",
      "\n",
      "4.Internal IDs & Indexes \n",
      "ChromaDB also stores:\n",
      "-->Unique IDs for each vector\n",
      "-->Index structures (for fast search)\n",
      "-->Collection information\n",
      "-->You usually don't interact with this directly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "ChromaDB stores 4 main things.\n",
    "\n",
    "1.Embeddings (Vectors) \n",
    "These are the numerical representations of your text.\n",
    "\n",
    "2.Original Text (Document Content)\n",
    "The actual text chunk---Not just the vector cause After similarity search, you need the original text to send to the LLM\n",
    "\n",
    "3.Metadata\n",
    "Metadata is extra information about each chunk\n",
    "\n",
    "4.Internal IDs & Indexes \n",
    "ChromaDB also stores:\n",
    "-->Unique IDs for each vector\n",
    "-->Index structures (for fast search)\n",
    "-->Collection information\n",
    "-->You usually don't interact with this directly\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeaa5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert vector store to retriever\n",
    "#create document chain\n",
    "#create rag chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c348ad31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='0e06feb1-fda8-430b-8d7e-d1fd3726263a', metadata={'source': 'data\\\\doc_0.txt'}, page_content='project-based approach, using tools such as Google Colab, Python libraries, and real-world datasets to gain deeper understanding. \\n     This approach helps translate abstract concepts into real implementations, especially in areas like regression, classification, and neural networks.'),\n",
       "  0.3926593065261841),\n",
       " (Document(id='846d1fb1-18fb-4726-a432-d378215521aa', metadata={'source': 'data\\\\doc_2.txt'}, page_content='Beyond traditional ML and DL, Sri enjoys exploring emerging technologies such as Generative AI, Agentic AI, chatbots, and multimodal systems. \\nThere is a strong ambition to build end-to-end AI systems, starting from raw data ingestion, moving through embeddings and vector search, and \\nultimately generating meaningful, context-aware responses using large language models. Sri is detail-oriented and\\n values updated, correct, and production-ready code, especially when working with fast-evolving'),\n",
       "  0.3947649598121643),\n",
       " (Document(id='23462511-8cc6-4cbb-bd5b-043f49e25227', metadata={'source': 'data\\\\doc_0.txt'}, page_content='Sri is a passionate and highly motivated learner who is actively transitioning into the fields of Machine Learning, Deep Learning, and Generative AI. \\n   With a strong curiosity about how intelligent systems function, Sri is focused on building \\n   solid practical foundations in AI, including Python programming, data structures, model training, and deployment workflows. Instead of limiting learning to theory, Sri\\n     strongly prefers a hands-on, project-based approach, using tools such as'),\n",
       "  0.40391331911087036)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"what is Deep Learning?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs\n",
    "\n",
    "\n",
    "#similarity search with scores\n",
    "results_scores=vectorstore.similarity_search_with_score(query,k=3)\n",
    "results_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7ab5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
      "\n",
      "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
      "\n",
      "- Lower scores = MORE similar (closer in vector space)\n",
      "- Score of 0 = identical vectors\n",
      "- Typical range: 0 to 2 (but can be higher)\n",
      "\n",
      "\n",
      "Cosine similarity (if configured):\n",
      "\n",
      "- Higher scores = MORE similar\n",
      "- Range: -1 to 1 (1 being identical)\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#### Understanding Similarity Scores\n",
    "print(\"\"\"\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b6f530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed94626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Large language models are a type of artificial intelligence that can process and generate human-like text. These models are typically trained on large datasets of text and are capable of understanding and generating language with a high degree of accuracy and fluency. They can be used for a wide range of natural language processing tasks, including text generation, translation, sentiment analysis, and more. These models have been a significant advancement in the field of AI and have led to improvements in various applications such as chatbots, language translation, and content generation. Some popular examples of large language models include OpenAI's GPT-3 and Google's BERT.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 12, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CywVcjqydnt4NFryt8y1DNtqbCp7V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bcb32-2fb7-7be0-8f1f-23ac68309cea-0', usage_metadata={'input_tokens': 12, 'output_tokens': 125, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response=llm.invoke(\"What is Large Language Models\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b363deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001F4A32DC690>, search_kwargs={})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retriever\n",
    "retriever=vectorstore.as_retriever(\n",
    "    search_kwarg={\"k\":3} ## Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b54c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c4c56d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
